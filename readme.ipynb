{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aleph Alpha Client\n",
    "\n",
    "[![PyPI version](https://badge.fury.io/py/aleph-alpha-client.svg)](https://pypi.org/project/aleph-alpha-client/)\n",
    "\n",
    "Interact with the Aleph Alpha API via Python\n",
    "\n",
    "> [Documentation of the HTTP API can be found here](https://docs.aleph-alpha.com/api/)\n",
    "\n",
    "## Installation\n",
    "\n",
    "The latest stable version is deployed to PyPi so you can install this package via pip.\n",
    "\n",
    "```sh\n",
    "pip install aleph-alpha-client\n",
    "```\n",
    "\n",
    "## Usage\n",
    "\n",
    "### Completion Multimodal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aleph_alpha_client import ImagePrompt, AlephAlphaClient\n",
    "import os\n",
    "\n",
    "client = AlephAlphaClient(\n",
    "    host=\"https://api.aleph-alpha.com\",\n",
    "    token=os.getenv(\"AA_TOKEN\")\n",
    ")\n",
    "\n",
    "# You need to choose a model with multimodal capabilities for this example.\n",
    "model = \"luminous-base\"\n",
    "url = \"https://cdn-images-1.medium.com/max/1200/1*HunNdlTmoPj8EKpl-jqvBA.png\"\n",
    "\n",
    "image = ImagePrompt.from_url(url)\n",
    "prompt = [\n",
    "    image,\n",
    "    \"Q: What does the picture show? A:\",\n",
    "]\n",
    "result = client.complete(model, prompt=prompt, maximum_tokens=20)\n",
    "\n",
    "print(result[\"completions\"][0][\"completion\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Evaluation text prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aleph_alpha_client import ImagePrompt, AlephAlphaClient\n",
    "import os\n",
    "\n",
    "client = AlephAlphaClient(\n",
    "    host=\"https://api.aleph-alpha.com\",\n",
    "    token=os.getenv(\"AA_TOKEN\")\n",
    ")\n",
    "\n",
    "model = \"luminous-base\"\n",
    "prompt = \"The api works\"\n",
    "result = client.evaluate(model, prompt=prompt, completion_expected=\" well\")\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Evaluation Multimodal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aleph_alpha_client import ImagePrompt, AlephAlphaClient\n",
    "import os\n",
    "\n",
    "client = AlephAlphaClient(\n",
    "    host=\"https://api.aleph-alpha.com\",\n",
    "    token=os.getenv(\"AA_TOKEN\")\n",
    ")\n",
    "\n",
    "# You need to choose a model with multimodal capabilities for this example.\n",
    "model = \"luminous-base\"\n",
    "\n",
    "url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/2008-09-24_Blockbuster_in_Durham.jpg/330px-2008-09-24_Blockbuster_in_Durham.jpg\"\n",
    "image = ImagePrompt.from_url(url)\n",
    "prompt = [\n",
    "    image,\n",
    "    \"Q: What is the name of the store?\\nA:\",\n",
    "]\n",
    "\n",
    "result = client.evaluate(model, prompt=prompt, completion_expected=\" Blockbuster Video\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Embedding text prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aleph_alpha_client import ImagePrompt, AlephAlphaClient, EmbeddingRequest\n",
    "import os\n",
    "\n",
    "client = AlephAlphaClient(\n",
    "    host=\"https://api.aleph-alpha.com\",\n",
    "    token=os.getenv(\"AA_TOKEN\")\n",
    ")\n",
    "\n",
    "model = \"luminous-base\"\n",
    "request = EmbeddingRequest(prompt=\"This is an example.\", layers=[-1], pooling=[\"mean\"])\n",
    "result = client.embed(model, request)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Embedding multimodal prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aleph_alpha_client import ImagePrompt, AlephAlphaClient\n",
    "import os\n",
    "\n",
    "client = AlephAlphaClient(\n",
    "    host=\"https://api.aleph-alpha.com\",\n",
    "    token=os.getenv(\"AA_TOKEN\")\n",
    ")\n",
    "\n",
    "# You need to choose a model with multimodal capabilities for this example.\n",
    "model = \"luminous-base\"\n",
    "\n",
    "url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/2008-09-24_Blockbuster_in_Durham.jpg/330px-2008-09-24_Blockbuster_in_Durham.jpg\"\n",
    "image = ImagePrompt.from_url(url)\n",
    "prompt = [\n",
    "    image,\n",
    "    \"Q: What is the name of the store?\\nA:\",\n",
    "]\n",
    "request = EmbeddingRequest(prompt=prompt, layers=[-1], pooling=[\"mean\"])\n",
    "result = client.embed(model, request)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Q&A with a Docx Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aleph_alpha_client import Document, AlephAlphaClient\n",
    "import os\n",
    "\n",
    "client = AlephAlphaClient(\n",
    "    host=\"https://api.aleph-alpha.com\",\n",
    "    token=os.getenv(\"AA_TOKEN\")\n",
    ")\n",
    "\n",
    "# You need to choose a model with qa support for this example.\n",
    "model = \"luminous-extended\"\n",
    "\n",
    "query = \"What is a computer program?\"\n",
    "docx_file = \"./tests/sample.docx\"\n",
    "document = Document.from_docx_file(docx_file)\n",
    "documents = [document]\n",
    "\n",
    "result = client.qa(model, query=query, documents=documents, maximum_tokens=64)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Q&A with a Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aleph_alpha_client import Document, AlephAlphaClient\n",
    "import os\n",
    "\n",
    "client = AlephAlphaClient(\n",
    "    host=\"https://api.aleph-alpha.com\",\n",
    "    token=os.getenv(\"AA_TOKEN\")\n",
    ")\n",
    "\n",
    "# You need to choose a model with qa support for this example.\n",
    "model = \"luminous-extended\"\n",
    "\n",
    "query = \"What is a computer program?\"\n",
    "prompt = \"In imperative programming, a computer program is a sequence of instructions in a programming language that a computer can execute or interpret.\"\n",
    "document = Document.from_text(prompt)\n",
    "documents = [document]\n",
    "\n",
    "result = client.qa(model, query=query, documents=documents, maximum_tokens=64)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Q&A with a multimodal prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aleph_alpha_client import Document, ImagePrompt, AlephAlphaClient\n",
    "import os\n",
    "\n",
    "client = AlephAlphaClient(\n",
    "    host=\"https://api.aleph-alpha.com\",\n",
    "    token=os.getenv(\"AA_TOKEN\")\n",
    ")\n",
    "\n",
    "# You need to choose a model with qa support and multimodal capabilities for this example.\n",
    "model = \"luminous-extended\"\n",
    "\n",
    "query = \"What is the name of the store?\"\n",
    "url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/2008-09-24_Blockbuster_in_Durham.jpg/330px-2008-09-24_Blockbuster_in_Durham.jpg\"\n",
    "image = ImagePrompt.from_url(url)\n",
    "prompt = [image]\n",
    "document = Document.from_prompt(prompt)\n",
    "documents = [document]\n",
    "\n",
    "result = client.qa(model, query=query, documents=documents, maximum_tokens=64)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Tokenize a text prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aleph_alpha_client import Document, ImagePrompt, AlephAlphaClient\n",
    "from aleph_alpha_client.tokenization import TokenizationRequest\n",
    "import os\n",
    "\n",
    "client = AlephAlphaClient(\n",
    "    host=\"https://api.aleph-alpha.com\",\n",
    "    token=os.getenv(\"AA_TOKEN\")\n",
    ")\n",
    "\n",
    "# You need to choose a model with qa support and multimodal capabilities for this example.\n",
    "model = \"luminous-extended\"\n",
    "request = TokenizationRequest(prompt=\"This is an example.\", tokens=True, token_ids=True)\n",
    "response = client.tokenize(model, request=request)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Detokenize a token IDs into text prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aleph_alpha_client import Document, ImagePrompt, AlephAlphaClient\n",
    "from aleph_alpha_client.detokenization import DetokenizationRequest\n",
    "import os\n",
    "\n",
    "client = AlephAlphaClient(\n",
    "    host=\"https://api.aleph-alpha.com\",\n",
    "    token=os.getenv(\"AA_TOKEN\")\n",
    ")\n",
    "\n",
    "# You need to choose a model with qa support and multimodal capabilities for this example.\n",
    "model = \"luminous-extended\"\n",
    "request = DetokenizationRequest(token_ids=[1730, 387, 300, 4377, 17])\n",
    "response = client.detokenize(model, request=request)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Testing\n",
    "\n",
    "Tests use pytests with (optional) coverage plugin. Install the locally cloned repo in editable mode with:\n",
    "\n",
    "```bash\n",
    "pip install -e .[test]\n",
    "```\n",
    "\n",
    "**Tests make api calls that reduce your quota!**\n",
    "\n",
    "### Run tests\n",
    "\n",
    "Tests can be run using pytest. Make sure to create a `.env` file with the following content:\n",
    "\n",
    "```env\n",
    "# test settings\n",
    "TEST_API_URL=https://test.api.aleph-alpha.com\n",
    "TEST_MODEL=luminous-base\n",
    "TEST_TOKEN=your_token\n",
    "```\n",
    "\n",
    "Instead of a token username and password can be used.\n",
    "\n",
    "```env\n",
    "# test settings\n",
    "TEST_API_URL=https://api.aleph-alpha.com\n",
    "TEST_MODEL=luminous-base\n",
    "TEST_USERNAME=your_username\n",
    "TEST_PASSWORD=your_password\n",
    "```\n",
    "\n",
    "* A coverage report can be created using the optional arguments --cov-report and --cov (see pytest documentation)\n",
    "* A subset of tests can be selected by pointing to the module within tests\n",
    "\n",
    "```bash\n",
    "# run all tests, output coverage report of aleph_alpha_client module in terminal\n",
    "pytest --cov-report term --cov=aleph_alpha_client tests\n",
    "pytest tests -v # start verbose\n",
    "```\n",
    "\n",
    "If an html coverage report has been created a simple http server can be run to serve static files.\n",
    "\n",
    "```bash\n",
    "python -m http.server --directory htmlcov 8000\n",
    "```\n",
    "\n",
    "## Update README\n",
    "\n",
    "> Do not change the README.md directly as it is generated from readme.ipynb \n",
    "\n",
    "1. `pip install -r requirements-dev.txt`\n",
    "\n",
    "2. To update the readme edit the notebook in your favorite jupyter editor and run all python cells to verify that the code examples still work.\n",
    "\n",
    "3. To generate a new README.md first remove all output cells from the Jupyter notebook and then execute the command: `jupyter nbconvert --to markdown readme.ipynb --output README.md`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1285231c71741bfec547062555f68dae52df95376b2ffb34687075df3ca42714"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
